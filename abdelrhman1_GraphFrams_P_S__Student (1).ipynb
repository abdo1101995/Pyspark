{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "779b346d",
      "metadata": {
        "id": "779b346d"
      },
      "source": [
        "## The following section is for Colab Users.\n",
        "### Just run the following code cells"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "id": "2zZUqqI8UnrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c3f565-78fc-4568-aa89-c19042aca65c"
      },
      "id": "2zZUqqI8UnrO",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7d73eb01",
      "metadata": {
        "id": "7d73eb01"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://bitbucket.org/habedi/datasets/raw/b6769c4664e7ff68b001e2f43bc517888cbe3642/spark/spark-3.0.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.2-bin-hadoop2.7.tgz\n",
        "!rm -rf spark-3.0.2-bin-hadoop2.7.tgz*\n",
        "!pip -q install findspark pyspark graphframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "299e0d6a",
      "metadata": {
        "id": "299e0d6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f162cd-c979-46f0-9c31-f95967fd88d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-29 12:52:59--  https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.0-s_2.12/graphframes-0.8.2-spark3.0-s_2.12.jar\n",
            "Resolving repos.spark-packages.org (repos.spark-packages.org)... 13.227.254.32, 13.227.254.25, 13.227.254.119, ...\n",
            "Connecting to repos.spark-packages.org (repos.spark-packages.org)|13.227.254.32|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 247882 (242K) [binary/octet-stream]\n",
            "Saving to: ‘/content/spark-3.0.2-bin-hadoop2.7/jars/graphframes-0.8.2-spark3.0-s_2.12.jar.1’\n",
            "\n",
            "\r          graphfram   0%[                    ]       0  --.-KB/s               \rgraphframes-0.8.2-s 100%[===================>] 242.07K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-06-29 12:52:59 (84.8 MB/s) - ‘/content/spark-3.0.2-bin-hadoop2.7/jars/graphframes-0.8.2-spark3.0-s_2.12.jar.1’ saved [247882/247882]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.0-s_2.12/graphframes-0.8.2-spark3.0-s_2.12.jar -P /content/spark-3.0.2-bin-hadoop2.7/jars/\n",
        "!cp /content/spark-3.0.2-bin-hadoop2.7/jars/graphframes-0.8.2-spark3.0-s_2.12.jar /content/spark-3.0.2-bin-hadoop2.7/graphframes-0.8.2-spark3.0-s_2.12.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ee0d39ec",
      "metadata": {
        "id": "ee0d39ec"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.2-bin-hadoop2.7\"\n",
        "os.environ[\"HADOOP_HOME\"] = os.environ[\"SPARK_HOME\"]\n",
        "\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"jupyter\"\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"] = \"notebook\"\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[*] pyspark-shell\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7136d8e6",
      "metadata": {
        "id": "7136d8e6"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "92f3e19b",
      "metadata": {
        "id": "92f3e19b"
      },
      "outputs": [],
      "source": [
        "!export PYSPARK_SUBMIT_ARGS=\"--master local[*] pyspark-shell\"\n",
        "!export PYSPARK_DRIVER_PYTHON=jupyter\n",
        "!export PYSPARK_DRIVER_PYTHON_OPTS=notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f1504ff4",
      "metadata": {
        "id": "f1504ff4"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from graphframes import *\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"GraphFrames\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "252db99a",
      "metadata": {
        "id": "252db99a"
      },
      "outputs": [],
      "source": [
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--packages graphframes:graphframes:0.8.1-spark3.0-s_2.12 pyspark-shell\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66232934",
      "metadata": {
        "id": "66232934"
      },
      "source": [
        "**************************************************************************\n",
        "**************************************************************************\n",
        "**************************************************************************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c90808ca",
      "metadata": {
        "id": "c90808ca"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2a0819b3",
      "metadata": {
        "id": "2a0819b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e5364d1c-66a5-417b-ee57-5478d71b1143"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>pre { white-space: pre !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "GxoyucbZXsAk"
      },
      "id": "GxoyucbZXsAk",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('depa').getOrCreate()"
      ],
      "metadata": {
        "id": "imS90KG_ZtRy"
      },
      "id": "imS90KG_ZtRy",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d7f57da0",
      "metadata": {
        "id": "d7f57da0"
      },
      "source": [
        "### Read departuredelays.csv in Edge DataFrame\n",
        "### Read airport-codes-na.txt in Vertix DataFrame (the separator is Tab i.e sep = '\\t' )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "631c334e",
      "metadata": {
        "id": "631c334e"
      },
      "source": [
        "#### The US flight delays data set has five columns:\n",
        "- The <b>date</b> column contains an integer like 02190925 . When converted, this maps to 02-19 09:25 am.\n",
        "- The <b>delay</b> column gives the delay in minutes between the scheduled and actual departure times. Early departures show negative numbers.\n",
        "- The <b>distance</b> column gives the distance in miles from the origin airport to the destination airport.\n",
        "- The <b>origin</b> column contains the origin IATA airport code.\n",
        "- The <b>destination</b> column contains the destination IATA airport code.\n",
        "\n",
        "#### The airport-codes data set has four columns:\n",
        "- The <b>IATA</b> column contains IATA airport code.\n",
        "- The <b>City, State, and Country</b> columns contains information about the airport location. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "30f02a5a",
      "metadata": {
        "id": "30f02a5a"
      },
      "outputs": [],
      "source": [
        "e=spark.read.csv('/content/departuredelays.csv', header='true', inferSchema='true', sep=',')\n",
        "v=spark.read.csv('/content/airport-codes-na.txt', header='true', inferSchema='true', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e.show(10)"
      ],
      "metadata": {
        "id": "8hYcummDaf16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76297a51-3ded-4de1-ab39-d2446bfa057a"
      },
      "id": "8hYcummDaf16",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+--------+------+-----------+\n",
            "|   date|delay|distance|origin|destination|\n",
            "+-------+-----+--------+------+-----------+\n",
            "|1011245|    6|     602|   ABE|        ATL|\n",
            "|1020600|   -8|     369|   ABE|        DTW|\n",
            "|1021245|   -2|     602|   ABE|        ATL|\n",
            "|1020605|   -4|     602|   ABE|        ATL|\n",
            "|1031245|   -4|     602|   ABE|        ATL|\n",
            "|1030605|    0|     602|   ABE|        ATL|\n",
            "|1041243|   10|     602|   ABE|        ATL|\n",
            "|1040605|   28|     602|   ABE|        ATL|\n",
            "|1051245|   88|     602|   ABE|        ATL|\n",
            "|1050605|    9|     602|   ABE|        ATL|\n",
            "+-------+-----+--------+------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v.show(10)"
      ],
      "metadata": {
        "id": "rA5WD7Z4elJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c11904d-307e-4ada-da49-4d6e3e8c13fb"
      },
      "id": "rA5WD7Z4elJY",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+-------+----+\n",
            "|       City|State|Country|IATA|\n",
            "+-----------+-----+-------+----+\n",
            "| Abbotsford|   BC| Canada| YXX|\n",
            "|   Aberdeen|   SD|    USA| ABR|\n",
            "|    Abilene|   TX|    USA| ABI|\n",
            "|      Akron|   OH|    USA| CAK|\n",
            "|    Alamosa|   CO|    USA| ALS|\n",
            "|     Albany|   GA|    USA| ABY|\n",
            "|     Albany|   NY|    USA| ALB|\n",
            "|Albuquerque|   NM|    USA| ABQ|\n",
            "| Alexandria|   LA|    USA| AEX|\n",
            "|  Allentown|   PA|    USA| ABE|\n",
            "+-----------+-----+-------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1d90463",
      "metadata": {
        "id": "e1d90463"
      },
      "source": [
        "### In the vertix DataFrame, drop any duplicated rows with the same  IATA code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "15571db4",
      "metadata": {
        "id": "15571db4"
      },
      "outputs": [],
      "source": [
        "v1=v.dropDuplicates([\"IATA\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v1.show()"
      ],
      "metadata": {
        "id": "jUShnYFGfT2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaafec68-cedf-4fca-894d-6f7306839494"
      },
      "id": "jUShnYFGfT2X",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+-------+----+\n",
            "|               City|State|Country|IATA|\n",
            "+-------------------+-----+-------+----+\n",
            "|         Binghamton|   NY|    USA| BGM|\n",
            "|            Lebanon|   NH|    USA| LEB|\n",
            "|           Montreal|   PQ| Canada| YUL|\n",
            "|         Dillingham|   AK|    USA| DLG|\n",
            "|International Falls|   MN|    USA| INL|\n",
            "|         Wolf Point|   MT|    USA| OLF|\n",
            "|        New Orleans|   LA|    USA| MSY|\n",
            "|            Toronto|   ON| Canada| YTO|\n",
            "|            Spokane|   WA|    USA| GEG|\n",
            "|              Havre|   MT|    USA| HVR|\n",
            "|            Burbank|   CA|    USA| BUR|\n",
            "|      Orange County|   CA|    USA| SNA|\n",
            "|             Dryden|   ON| Canada| YHD|\n",
            "|         Fort Dodge|   IA|    USA| FOD|\n",
            "|          Green Bay|   WI|    USA| GRB|\n",
            "|        Great Falls|   MT|    USA| GTF|\n",
            "|              Homer|   AK|    USA| HOM|\n",
            "|        Idaho Falls|   ID|    USA| IDA|\n",
            "|      Sioux Lookout|   ON| Canada| YXL|\n",
            "|       Grand Rapids|   MI|    USA| GRR|\n",
            "+-------------------+-----+-------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d1dea8",
      "metadata": {
        "id": "83d1dea8"
      },
      "source": [
        "### In the edges DataFrame:\n",
        "- Rename the <b>date</b> columns to become <b>tripid</b>.\n",
        "- Rename the <b>origin</b> columns to become <b>src</b>.\n",
        "- Rename the <b>destination</b> columns to become <b>dst</b>."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType"
      ],
      "metadata": {
        "id": "Zkeare6orauJ"
      },
      "id": "Zkeare6orauJ",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5319e844",
      "metadata": {
        "id": "5319e844"
      },
      "outputs": [],
      "source": [
        "e1 = e.withColumnRenamed(\"date\",\"tripid\") \\\n",
        "    .withColumnRenamed(\"origin\",\"src\")\\\n",
        "    .withColumnRenamed(\"destination\",\"dst\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e2=e1.withColumn(\"delay\",e1.delay.cast(IntegerType()))"
      ],
      "metadata": {
        "id": "qcZ3pLjSp9OK"
      },
      "id": "qcZ3pLjSp9OK",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e2.printSchema()"
      ],
      "metadata": {
        "id": "VqLGl-wggp7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae32540-5448-46d6-fdf0-0a5a135114c7"
      },
      "id": "VqLGl-wggp7x",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- tripid: integer (nullable = true)\n",
            " |-- delay: integer (nullable = true)\n",
            " |-- distance: integer (nullable = true)\n",
            " |-- src: string (nullable = true)\n",
            " |-- dst: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "260660dc",
      "metadata": {
        "id": "260660dc"
      },
      "source": [
        "### In the Vertix DataFrame:\n",
        "- Rename the <b>IATA</b> columns to become <b>id</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "42846969",
      "metadata": {
        "scrolled": false,
        "id": "42846969"
      },
      "outputs": [],
      "source": [
        "v2=v1.withColumnRenamed('IATA','id')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2.printSchema()"
      ],
      "metadata": {
        "id": "OXazLW8Kg1RH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c22f416-ded5-42ad-f25f-666fdc083081"
      },
      "id": "OXazLW8Kg1RH",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b50a1fe",
      "metadata": {
        "id": "4b50a1fe"
      },
      "source": [
        "### Create GraphFrame from Vertix and Edges DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "72be9d09",
      "metadata": {
        "id": "72be9d09"
      },
      "outputs": [],
      "source": [
        "from graphframes import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gf = GraphFrame(v2,e2)"
      ],
      "metadata": {
        "id": "hDOj_98tg7te"
      },
      "id": "hDOj_98tg7te",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "abd2ebc6",
      "metadata": {
        "id": "abd2ebc6"
      },
      "source": [
        "### Determine the number of airports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f38688c9",
      "metadata": {
        "id": "f38688c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff72ec2-89e0-4c43-b940-8aa93df9291b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+--------+---+---+\n",
            "| tripid|delay|distance|src|dst|\n",
            "+-------+-----+--------+---+---+\n",
            "|1011245|    6|     602|ABE|ATL|\n",
            "|1020600|   -8|     369|ABE|DTW|\n",
            "|1021245|   -2|     602|ABE|ATL|\n",
            "|1020605|   -4|     602|ABE|ATL|\n",
            "|1031245|   -4|     602|ABE|ATL|\n",
            "|1030605|    0|     602|ABE|ATL|\n",
            "|1041243|   10|     602|ABE|ATL|\n",
            "|1040605|   28|     602|ABE|ATL|\n",
            "|1051245|   88|     602|ABE|ATL|\n",
            "|1050605|    9|     602|ABE|ATL|\n",
            "|1061215|   -6|     602|ABE|ATL|\n",
            "|1061725|   69|     602|ABE|ATL|\n",
            "|1061230|    0|     369|ABE|DTW|\n",
            "|1060625|   -3|     602|ABE|ATL|\n",
            "|1070600|    0|     369|ABE|DTW|\n",
            "|1071725|    0|     602|ABE|ATL|\n",
            "|1071230|    0|     369|ABE|DTW|\n",
            "|1070625|    0|     602|ABE|ATL|\n",
            "|1071219|    0|     569|ABE|ORD|\n",
            "|1080600|    0|     369|ABE|DTW|\n",
            "+-------+-----+--------+---+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gf.edges.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "435187a8",
      "metadata": {
        "id": "435187a8"
      },
      "source": [
        "### Determine the number of trips "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1tuLjtP-owVa"
      },
      "id": "1tuLjtP-owVa",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gf.edges.select('tripid').count()"
      ],
      "metadata": {
        "id": "cXVH2MEVm4AL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c315e3f-be59-49a9-e0a1-448efbc4d903"
      },
      "id": "cXVH2MEVm4AL",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "524644"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dec8731f",
      "metadata": {
        "id": "dec8731f"
      },
      "source": [
        "### What is the longest delay?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N03-l3f2n3JC"
      },
      "id": "N03-l3f2n3JC",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "df3d6aac",
      "metadata": {
        "id": "df3d6aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c05c88d-2d61-4d0b-ccdb-83975c0985fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|max(delay)|\n",
            "+----------+\n",
            "|      1560|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gf.edges.groupBy().max(\"delay\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "202d888c",
      "metadata": {
        "id": "202d888c"
      },
      "source": [
        "### Find out the number of delayed flights vs. early flights (flights that departed before actual time)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "early flights "
      ],
      "metadata": {
        "id": "RYRS3X9msejK"
      },
      "id": "RYRS3X9msejK"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "7cdd7ff7",
      "metadata": {
        "id": "7cdd7ff7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc92c8c1-cee3-4526-c367-d1a6cb6d45f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233465"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "gf.edges.filter('delay<0').count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "delayed flights"
      ],
      "metadata": {
        "id": "5I4q6K2Vs-Xx"
      },
      "id": "5I4q6K2Vs-Xx"
    },
    {
      "cell_type": "code",
      "source": [
        "gf.edges.filter('delay>0').count()"
      ],
      "metadata": {
        "id": "4pj0IeccsolJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7698ae6a-11c7-4ebf-ed04-8f592959e212"
      },
      "id": "4pj0IeccsolJ",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "231718"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30961bc3",
      "metadata": {
        "id": "30961bc3"
      },
      "source": [
        "### What flight destinations departing SFO are most likely to have significant delays? Select the top 10\n",
        "#### Hint: you should get the average delay for each destination for trips that depart from SFO only"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc"
      ],
      "metadata": {
        "id": "GdmgHjK2wkpH"
      },
      "id": "GdmgHjK2wkpH",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "afdc6842",
      "metadata": {
        "id": "afdc6842",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ebd2907-a467-49a3-991e-f7c2c6c2e4a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+------------------+\n",
            "|src|dst|        avg(delay)|\n",
            "+---+---+------------------+\n",
            "|SFO|COS|             68.25|\n",
            "|SFO|SUN|60.714285714285715|\n",
            "|SFO|MSY|              54.0|\n",
            "|SFO|OTH|              52.0|\n",
            "|SFO|LGB|          50.53125|\n",
            "|SFO|PIT|              49.6|\n",
            "|SFO|MSP| 48.44736842105263|\n",
            "|SFO|JAC|              47.9|\n",
            "|SFO|ASE| 45.44444444444444|\n",
            "|SFO|JFK| 45.13304721030043|\n",
            "+---+---+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gf.edges.filter(\"src = 'SFO' and delay > 0\").groupBy(\"src\", \"dst\"). avg(\"delay\").sort(desc(\"avg(delay)\")).show(10)\n",
        "  \n",
        " \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d46665",
      "metadata": {
        "id": "71d46665"
      },
      "source": [
        "### Find the Incoming connections to the airport sorted in Desc. order."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gf.degrees.sort(desc(\"degree\")).show()"
      ],
      "metadata": {
        "id": "CD5WIJ_9xvB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b10d436-527b-4794-8f48-3f0c1ddb6936"
      },
      "id": "CD5WIJ_9xvB1",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "| id|degree|\n",
            "+---+------+\n",
            "|ATL| 91975|\n",
            "|DFW| 48986|\n",
            "|ORD| 44354|\n",
            "|LAX| 37940|\n",
            "|DEN| 36883|\n",
            "|IAH| 30625|\n",
            "|SFO| 28120|\n",
            "|PHX| 27793|\n",
            "|BOS| 24817|\n",
            "|LAS| 23102|\n",
            "|CLT| 20724|\n",
            "|MCO| 19790|\n",
            "|EWR| 19712|\n",
            "|LGA| 18467|\n",
            "|SLC| 17951|\n",
            "|JFK| 16712|\n",
            "|MSP| 16381|\n",
            "|SEA| 16297|\n",
            "|BWI| 15890|\n",
            "|DTW| 15872|\n",
            "+---+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "c28925c3",
      "metadata": {
        "id": "c28925c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81f7e2f-5711-4642-aebb-bc8314e863b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|inDegree|\n",
            "+---+--------+\n",
            "|ATL|   33185|\n",
            "|DFW|   25498|\n",
            "|ORD|   22857|\n",
            "|LAX|   19459|\n",
            "|DEN|   18906|\n",
            "|IAH|   16044|\n",
            "|SFO|   14570|\n",
            "|PHX|   14450|\n",
            "|LAS|   12052|\n",
            "|CLT|   10956|\n",
            "|MCO|   10584|\n",
            "|EWR|   10445|\n",
            "|LGA|    9937|\n",
            "|SLC|    9266|\n",
            "|JFK|    8834|\n",
            "|BOS|    8792|\n",
            "|BWI|    8713|\n",
            "|SEA|    8517|\n",
            "|MIA|    8335|\n",
            "|DTW|    8330|\n",
            "+---+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gf.inDegrees.sort(desc(\"inDegree\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b6509d",
      "metadata": {
        "id": "d1b6509d"
      },
      "source": [
        "### Find the Outgoing connections from the airport sorted in Desc. order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "631af51d",
      "metadata": {
        "id": "631af51d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb08e3d-3955-434c-d2e8-d0d8da6901d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+\n",
            "| id|outDegree|\n",
            "+---+---------+\n",
            "|ATL|    58790|\n",
            "|DFW|    23488|\n",
            "|ORD|    21497|\n",
            "|LAX|    18481|\n",
            "|DEN|    17977|\n",
            "|BOS|    16025|\n",
            "|IAH|    14581|\n",
            "|SFO|    13550|\n",
            "|PHX|    13343|\n",
            "|LAS|    11050|\n",
            "|CLT|     9768|\n",
            "|EWR|     9267|\n",
            "|MCO|     9206|\n",
            "|BNA|     8870|\n",
            "|SLC|     8685|\n",
            "|LGA|     8530|\n",
            "|MSP|     8085|\n",
            "|JFK|     7878|\n",
            "|SEA|     7780|\n",
            "|DTW|     7542|\n",
            "+---+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gf.outDegrees.sort(desc(\"outDegree\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbec58ce",
      "metadata": {
        "id": "fbec58ce"
      },
      "source": [
        "### Use motif finding to answer this question: which delays could we blame on SFO?\n",
        "#### Hint: this practically means that SFO is a transit station"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "db17f3df",
      "metadata": {
        "id": "db17f3df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433b0c98-1044-431a-fa8c-35b7aaf7ff3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                   a|                  ab|                   b|                  bc|                   c|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|[Albuquerque, NM,...|[1020600, 0, 779,...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Albuquerque, NM,...|[1210815, -12, 77...|[San Francisco, C...|[1211508, 593, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1011635, -15, 21...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1012016, -4, 217...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1020531, -2, 217...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1020948, -11, 21...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1021506, -3, 217...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1021318, -9, 217...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1020837, 12, 217...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1201703, -10, 21...|[San Francisco, C...|[1211508, 593, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1210545, 0, 217,...|[San Francisco, C...|[1211508, 593, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1211503, -10, 21...|[San Francisco, C...|[1211508, 593, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1210948, 28, 217...|[San Francisco, C...|[1211508, 593, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1211316, 9, 217,...|[San Francisco, C...|[1211508, 593, 22...|[New York, NY, US...|\n",
            "|[Eureka, CA, USA,...|[1210838, 91, 217...|[San Francisco, C...|[1211508, 593, 22...|[New York, NY, US...|\n",
            "|[Anchorage, AK, U...|[1012330, -4, 175...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Atlanta, GA, USA...|[1012130, 24, 185...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Atlanta, GA, USA...|[1011625, 6, 1859...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Atlanta, GA, USA...|[1021106, 26, 185...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "|[Atlanta, GA, USA...|[1020944, 7, 1859...|[San Francisco, C...|[1021507, 536, 22...|[New York, NY, US...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gf.find(\"(a)-[ab]->(b); (b)-[bc]->(c)\").filter(\"(b.id = 'SFO') and (ab.delay > 500 or bc.delay > 500) and bc.tripid > ab.tripid and bc.tripid < ab.tripid + 10000\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc1ece96",
      "metadata": {
        "id": "cc1ece96"
      },
      "source": [
        "### Determine Airport Ranking in Desc. order using PageRank algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "f754d545",
      "metadata": {
        "id": "f754d545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533cef3b-5236-4084-90e6-6f0477b908fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+-------+---+------------------+\n",
            "|          City|State|Country| id|          pagerank|\n",
            "+--------------+-----+-------+---+------------------+\n",
            "|       Atlanta|   GA|    USA|ATL|27.727899400710534|\n",
            "|        Dallas|   TX|    USA|DFW| 20.26679805190053|\n",
            "|       Chicago|   IL|    USA|ORD|19.412400365738495|\n",
            "|        Denver|   CO|    USA|DEN|14.542386215539732|\n",
            "|   Los Angeles|   CA|    USA|LAX|13.534796821839427|\n",
            "|       Houston|   TX|    USA|IAH|11.708716655367548|\n",
            "| San Francisco|   CA|    USA|SFO|10.693019052556826|\n",
            "|       Phoenix|   AZ|    USA|PHX| 9.849017406034136|\n",
            "|Salt Lake City|   UT|    USA|SLC|  8.78494058676923|\n",
            "|     Las Vegas|   NV|    USA|LAS|  8.03687122322553|\n",
            "|       Seattle|   WA|    USA|SEA| 7.086312995684949|\n",
            "|     Charlotte|   NC|    USA|CLT| 6.967069267775819|\n",
            "|        Newark|   NJ|    USA|EWR| 6.748345144738438|\n",
            "|       Orlando|   FL|    USA|MCO| 6.604209836084269|\n",
            "|   Minneapolis|   MN|    USA|MSP| 6.496808728249724|\n",
            "|      New York|   NY|    USA|LGA|   6.3988253840205|\n",
            "|       Detroit|   MI|    USA|DTW|6.1851510874902695|\n",
            "|        Boston|   MA|    USA|BOS| 5.806465227700622|\n",
            "|     Baltimore|   MD|    USA|BWI| 5.397789324255751|\n",
            "|      New York|   NY|    USA|JFK|5.3519426552731195|\n",
            "+--------------+-----+-------+---+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gf.pageRank(resetProbability=0.15 , tol = 0.01).vertices.orderBy(desc(\"pagerank\")).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe1e7648",
      "metadata": {
        "id": "fe1e7648"
      },
      "source": [
        "## Determine the most popular flights (single city hops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "da4b3306",
      "metadata": {
        "id": "da4b3306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2e4f8e-eb9c-428c-b799-3de15bd7b67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+------------+\n",
            "|src|dst|count(delay)|\n",
            "+---+---+------------+\n",
            "|ATL|LGA|        1620|\n",
            "|ATL|MCO|        1373|\n",
            "|BOS|DCA|        1290|\n",
            "|ATL|FLL|        1176|\n",
            "|ATL|DFW|        1155|\n",
            "|ATL|TPA|        1117|\n",
            "|SFO|LAX|        1109|\n",
            "|ATL|DCA|        1108|\n",
            "|LAX|SFO|        1092|\n",
            "|ATL|MIA|        1092|\n",
            "+---+---+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gf.edges.groupBy('src','dst').agg({'delay': 'count'}).sort(desc(\"count(delay)\")).show(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ebb5e18",
      "metadata": {
        "id": "8ebb5e18"
      },
      "source": [
        "### Find and Save a Subragph that obtained from the following pattern:\n",
        "#### The flight starts from an airport and return back to the same airport through 2 other airports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "00361946",
      "metadata": {
        "id": "00361946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e11c8224-059b-4c80-b9b3-131a8ac2bc5f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-9311420b3ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"(v1)-[e1]->(v2); (v2)-[e2]->(v3);(v3)-[e3] ->(v1)\"\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.2-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \"\"\"\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.2-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.2-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.2-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o160.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 142 in stage 964.0 failed 1 times, most recent failure: Lost task 142.0 in stage 964.0 (TID 20167, 566b6d9a7dd1, executor driver): java.io.IOException: No space left on device\n\tat java.base/java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.base/java.io.FileOutputStream.write(FileOutputStream.java:354)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:59)\n\tat java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)\n\tat java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:127)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:223)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:176)\n\tat java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)\n\tat java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:127)\n\tat java.base/java.io.DataOutputStream.write(DataOutputStream.java:107)\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.writeToStream(UnsafeRow.java:539)\n\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$1.writeValue(UnsafeRowSerializer.scala:69)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:249)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:158)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:462)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:465)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2135)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2154)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3627)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2697)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2697)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2904)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:300)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:337)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.io.IOException: No space left on device\n\tat java.base/java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.base/java.io.FileOutputStream.write(FileOutputStream.java:354)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:59)\n\tat java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)\n\tat java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:127)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:223)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:176)\n\tat java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)\n\tat java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:127)\n\tat java.base/java.io.DataOutputStream.write(DataOutputStream.java:107)\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.writeToStream(UnsafeRow.java:539)\n\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$1.writeValue(UnsafeRowSerializer.scala:69)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:249)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:158)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:462)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:465)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ],
      "source": [
        "gf.find(\"\"\"(v1)-[e1]->(v2); (v2)-[e2]->(v3);(v3)-[e3] ->(v1)\"\"\").show()\n",
        "               "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "abdelrhman1_GraphFrams_P.S._Student.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}